# 容器内存

容器在系统中被杀掉，只可能是容器中的所有进程使用了太多的内存，超过了容器在 Memory Cgroup 里的内存限制。这时 Linux 系统就会主动杀死容器中的一个进程，往往这会导致整个容器的退出。

## OOM Killer

在 Linux 系统里内存不足时，就需要杀死一个正在运行的进程来释放一些内存，是一种内存过载后的保护机制，通过牺牲个别的进程，来保证整个节点的内存不会被全部消耗掉。

Linux 进程在调用 `malloc()` 来申请内存是的申请策略是，允许进程在申请内存的时候 overcommit ，就是说允许进程申请超过实际物理内存上限的内存。

> 比如说，节点上的空闲物理内存只有 512MB 了，但是如果一个进程调用 `malloc()` 申请了 600MB，那么这次申请还是被允许的。因为 `malloc()` 申请的是内存的虚拟地址，系统只是给了程序一个地址范围，由于没有写入数据，所以程序并没有得到真正的物理内存。物理内存只有程序真的往这个地址写入数据的时候，才会分配给程序。

overcommit 的内存申请模式：

- 好处：有效提高系统的内存利用率
- 不足：遇到内存不够时，会杀死某个正在运行的进程

在发生 OOM 时 Linux 内核里有一个 `oom_badness()` 函数，它定义了选择杀死进程的标准，涉及两个条件：

1. 进程已经使用的物理内存页面数
2. 每个进程的 OOM 校准值 `oom_score_adj`。在 /proc 文件系统中，每个进程都有一个 `/proc/<pid>/oom_score_adj` 的接口文件。可以在这个文件中输入 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。

计算公式：`系统总的可用页面数 X 进程的 oom_score_adj + 进程已使用物理内存页面数`，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大。

## Memory Cgroup

Memory Cgroup 的作用是对一组进程的 Memory 使用做限制。Memory Cgroup 的虚拟文件系统的挂载点一般在 "`/sys/fs/cgroup/memory`" 这个目录下，可以在 Memory Cgroup 的挂载点目录下，创建一个子目录作为控制组。控制组之间是树状的层级结构，在这个结构中，父节点的控制组里的 `memory.limit_in_bytes` 值，可以限制它的子节点中所有进程的内存使用。

每一个控制组下面有不少参数，这里主要看与 OOM 最相关的 3 个参数：

- memory.limit_in_bytes：是每个控制组里最重要的参数，限制一个控制组里所有进程可使用内存的最大值。
- memory.oom_control：当控制组中所有进程内存使用总和达到上限值时，决定会不会触发 OOM Killer，缺省值是会触发 OOM Killer 从而杀掉某个进程，设置为 1 表示不触发。
- memory.usage_in_bytes：只读参数，表示当前控制组里所有进程实际使用的内存总和。

计算公式：`控制组中总的可用页面 X 进程的 oom_score_adj + 进程已经使用的物理内存页面数`，所得值最大的进程，就会被系统选中杀死。

对于每个容器创建后，系统都会为它建立一个 Memory Cgroup 的控制组，容器的所有进程都在这个控制组里。可以通过查看内核日志判断容器是否发生 OOM，执行 `journalctl -k` 或者直接查看日志文件 `/var/log/message`,当容器发生 OOM Kill 的时候，内核会输出下面的这段信息，大致包含下面这三部分的信息：

1. 容器里每一个进程使用的内存页面数量。在"rss(Resident Set Size)"列里，指进程真正在使用的物理内存页面数量。
2. "`oom-kill:`" 列出了发生 OOM 的 Memroy Cgroup 的控制组，从控制组的信息中知道 OOM 是在哪个容器发生的。
3. "`Memory cgroup out of memory: Killed process <pid> (mem_alloc)`" 显示最终被 OOM Killer 杀死的进程

分析 OOM 的原因：

1. 进程本身需要很大的内存，`memory.limit_in_bytes` 里的内存上限值设置小了。
2. 进程的代码中有 Bug，导致内存泄漏，进程内存使用到达了 Memory Cgroup 中的上限。
